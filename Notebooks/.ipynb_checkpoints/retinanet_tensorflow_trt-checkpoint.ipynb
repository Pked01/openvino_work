{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T05:42:51.231734Z",
     "start_time": "2019-08-17T05:42:31.812093Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import subprocess,sys\n",
    "from keras import backend as K\n",
    "from keras_retinanet import models\n",
    "import tensorflow as tf\n",
    "import cv2,os,datetime\n",
    "import numpy as np\n",
    "import time\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "import pandas as pd\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import IPython.display as Disp\n",
    "\n",
    "from keras_retinanet import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now()\n",
    "file_name = t.strftime(\"%d_%m_%Y_%H_%M_%S_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T05:24:06.505817Z",
     "start_time": "2019-06-14T05:24:06.501743Z"
    }
   },
   "outputs": [],
   "source": [
    "####Get inference model\n",
    "model_name = \"resnet50_csv_28.h5\"\n",
    "retinanet_snapshot = \"../../../dataset/helmet_n_vest/snapshots/\"+model_name\n",
    "inference_model = \"../../../model_with_worker/05_06_2019_09_24_40_resnet50_csv_50.pb\"\n",
    "inference_model_tensorflow = \"../../../model_with_worker/05_06_2019_09_24_40_resnet50_csv_50.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T05:42:51.236507Z",
     "start_time": "2019-08-17T05:42:51.233509Z"
    }
   },
   "outputs": [],
   "source": [
    "def snapshot_to_inference_retinanet(input_model_name,output_model_name,env='cv_p35'):\n",
    "    ! retinanet-convert-model {input_model_name} {output_model_name}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T05:42:51.426692Z",
     "start_time": "2019-08-17T05:42:51.238356Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_snapshot_to_protobuf(input_model_name, output_model_name,save_graph_def=False):\n",
    "    !{sys.executable} keras_to_tensorflow.py --input_model={input_model_name}  --output_model={output_model_name} --save_graph_def={save_graph_def}\n",
    "#     subprocess.call(['python keras_to_tensorflow.py --input_model=\"../../retinanet/snapshots_1/resnet50_csv_19.h5\"  --output_model=\"model.pb\"'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T05:42:51.613600Z",
     "start_time": "2019-08-17T05:42:51.428315Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_graph(frozen_model_file):\n",
    "    \"\"\"\n",
    "    returns graphdef(unserialized) object\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(frozen_model_file,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_snapshot = '../model_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-05-07 09:39:44.252063: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-07 09:39:44.291165: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2019-05-07 09:39:44.291212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: ip-172-31-20-69\n",
      "2019-05-07 09:39:44.291228: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: ip-172-31-20-69\n",
      "2019-05-07 09:39:44.291274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 410.104.0\n",
      "2019-05-07 09:39:44.291311: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 410.104.0\n",
      "2019-05-07 09:39:44.291325: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 410.104.0\n",
      "2019-05-07 09:39:44.297282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300020000 Hz\n",
      "2019-05-07 09:39:44.301715: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x43ad4e0 executing computations on platform Host. Devices:\n",
      "2019-05-07 09:39:44.301749: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "WARNING:tensorflow:From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0507 09:40:06.067628 139871028786944 deprecation.py:323] From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2019-05-07 09:40:09.395861: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-07 09:40:09.559934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-05-07 09:40:09.560408: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x76b1bb0 executing computations on platform CUDA. Devices:\n",
      "2019-05-07 09:40:09.560439: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-05-07 09:40:09.562725: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300020000 Hz\n",
      "2019-05-07 09:40:09.574770: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x771b9e0 executing computations on platform Host. Devices:\n",
      "2019-05-07 09:40:09.574799: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-05-07 09:40:09.575050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:1e.0\n",
      "totalMemory: 15.75GiB freeMemory: 5.71GiB\n",
      "2019-05-07 09:40:09.575085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-05-07 09:40:09.575684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-05-07 09:40:09.575710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-05-07 09:40:09.575728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-05-07 09:40:09.575904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5543 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\n",
      "/home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "I0507 09:40:12.552302 139871028786944 keras_to_tensorflow.py:131] Converted output node names are: ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3', 'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3', 'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3']\n",
      "I0507 09:40:13.360538 139871028786944 keras_to_tensorflow.py:142] Saved the graph definition in ascii format at ../../../trained_models/helmet_n_vest/retinanet/inference_model/07_05_2019_09_34_17_resnet50_csv_28.pbtxt\n",
      "WARNING:tensorflow:From keras_to_tensorflow.py:158: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "W0507 09:40:13.398160 139871028786944 deprecation.py:323] From keras_to_tensorflow.py:158: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "W0507 09:40:13.398385 139871028786944 deprecation.py:323] From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 306 variables.\n",
      "I0507 09:40:13.600224 139871028786944 graph_util_impl.py:268] Froze 306 variables.\n",
      "INFO:tensorflow:Converted 306 variables to const ops.\n",
      "I0507 09:40:13.793185 139871028786944 graph_util_impl.py:301] Converted 306 variables to const ops.\n",
      "I0507 09:40:14.737149 139871028786944 keras_to_tensorflow.py:163] Saved the freezed graph at ../../../trained_models/helmet_n_vest/retinanet/inference_model/07_05_2019_09_34_17_resnet50_csv_28.pb\n"
     ]
    }
   ],
   "source": [
    "snapshot_to_inference_retinanet(retinanet_snapshot, inference_model)\n",
    "convert_snapshot_to_protobuf(inference_model, inference_model_tensorflow,save_graph_def=True)\n",
    "Disp.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating tensorrt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T05:24:19.287170Z",
     "start_time": "2019-06-14T05:24:19.283874Z"
    }
   },
   "outputs": [],
   "source": [
    "model_input = 'input_1:0'\n",
    "model_output = ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T05:25:01.554794Z",
     "start_time": "2019-06-14T05:24:43.055562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running against TensorRT version 5.0.2\n"
     ]
    }
   ],
   "source": [
    "precision = \"FP16\"\n",
    "batch_size=10\n",
    "workspace_size=1 << 27\n",
    "trt_graph = trt.create_inference_graph(get_graph(inference_model_tensorflow),model_output,\\\n",
    "                                       precision_mode=precision,max_workspace_size_bytes=workspace_size,\\\n",
    "                                      max_batch_size=batch_size,is_dynamic_op=True)\n",
    "\n",
    "with tf.gfile.GFile(inference_model_tensorflow.replace('inference_model','tensorrt_model').replace('.pb','_precision='+precision+'_batchsize='+str(batch_size)+'_trt.pb'),'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T05:38:09.811873Z",
     "start_time": "2019-06-14T05:38:09.673639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numb. of all_nodes in frozen graph: 2011\n",
      "numb. of trt_engine_nodes in TensorRT graph: 56\n",
      "numb. of all_nodes in TensorRT graph: 1322\n"
     ]
    }
   ],
   "source": [
    "# check how many ops of the original frozen model\n",
    "all_nodes = len([1 for n in get_graph(inference_model_tensorflow).node])\n",
    "print(\"numb. of all_nodes in frozen graph:\", all_nodes)\n",
    "\n",
    "# check how many ops that is converted to TensorRT engine\n",
    "trt_engine_nodes = len([1 for n in trt_graph.node if str(n.op) == 'TRTEngineOp'])\n",
    "print(\"numb. of trt_engine_nodes in TensorRT graph:\", trt_engine_nodes)\n",
    "all_nodes = len([1 for n in trt_graph.node])\n",
    "print(\"numb. of all_nodes in TensorRT graph:\", all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "cv_p36",
   "language": "python",
   "name": "cv_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
