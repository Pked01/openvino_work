{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9261f274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T13:04:52.241807Z",
     "start_time": "2021-05-23T13:04:52.238174Z"
    }
   },
   "outputs": [],
   "source": [
    "import time,cv2,os,glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import IPython.display as Disp\n",
    "import support_utility_openvino\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de4a268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T13:04:52.580894Z",
     "start_time": "2021-05-23T13:04:52.573874Z"
    }
   },
   "outputs": [],
   "source": [
    "person_detection_model_path = '/home/acer/Documents/models/frozen_inference_graph_faster_rcnn_19.xml'\n",
    "num_requests = 4\n",
    "# base_xml_path = config.BASE_ANNOTATION_XML_PATH\n",
    "channel = '/media/acer/shared/aws-s3/dna-computer-vision/COMPUTER_VISION/SORTED_DATASET/HINDALCO_TRIAL/CLADDING/TALOJA/data/INGOT_TILTER_VIEW/18_02_2021/test_videos/Wrong Arrow detection Trail 3 CROPPED.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9c610f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-23T13:04:53.313119Z",
     "start_time": "2021-05-23T13:04:53.085925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices :  ['CPU', 'GNA', 'GPU']\n",
      "OPTIMIZATION_CAPABILITIES for CPU:  ['FP32', 'FP16', 'INT8', 'BIN']\n",
      "model inputs : dict_keys(['image_info', 'image_tensor'])\n",
      "model outputs :  dict_keys(['detection_output'])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d05bfbc4d941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mperson_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupport_utility_openvino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mperson_detection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperson_detection_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutput_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupport_utility_openvino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/personal/gitlab/Aditya-Birla-Group/Computer-Vision/UTCL-Hirmi/support_utility_openvino.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self, model_path, device, DYN_BATCH_ENABLED, max_batch_dyn, input_format)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"H\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "person_detection_model = support_utility_openvino.async_infer(4)\n",
    "person_detection_model.load_model(model_path=person_detection_model_path,device=\"CPU\")\n",
    "output_support = support_utility_openvino.create_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d80844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41da8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12eb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(base_xml_path)\n",
    "xmlRoot = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53db0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_detection_model.reinit_model()\n",
    "# helmet_vest_model.reinit_model()\n",
    "fps = []\n",
    "thresh_person = .2\n",
    "thresh_hv = .2\n",
    "cap = cv2.VideoCapture(channel)\n",
    "offset = 20\n",
    "resolution_thresh_range =[0.001,.4] ##percentage threshold(on resolution) for person detection\n",
    "\n",
    "write_video = False\n",
    "if write_video:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\"output.mp4\",fourcc, 20, (int(cap.get(3)),int(cap.get(4))))\n",
    "\n",
    "COUNT_ID = 2\n",
    "\n",
    "image = None\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    #print(\"Frame no: \", cap.get(1))\n",
    "    frame_no = int(cap.get(1))\n",
    "    if not ret:\n",
    "        break\n",
    "    masked_frame = frame.copy()\n",
    "    \n",
    "    frame_name = 'frame_'+str(frame_no).zfill(6)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    person_detection_model.predict(masked_frame,attr=frame)\n",
    "    if person_detection_model.frame_processed>=person_detection_model.num_requests:\n",
    "        masked_frame,orig_frame,res_person = person_detection_model.postprocess_op()\n",
    "        cropped_frames,updated_bbox,res_person_filt = output_support.trim_frame_with_result(orig_frame,res_person[0],offset=offset,\\\n",
    "                                                                                            return_results=True,threshold=thresh_person,resolution_thresh_range =resolution_thresh_range )\n",
    "        \n",
    "        h, w = orig_frame.shape[:2]\n",
    "        \n",
    "        image = ET.Element('image')\n",
    "        image.attrib['id'] = str(frame_no)\n",
    "        image.attrib['name'] = frame_name\n",
    "        image.attrib['width'] = str(w)\n",
    "        image.attrib['height'] = str(h)\n",
    "\n",
    "        cv2.putText(orig_frame, \"Frame Count: \"+str(frame_no), (w-1000, 100), 1, 2, (255, 0, 233), 3)\n",
    "        \n",
    "        for b in updated_bbox:\n",
    "            x1 = b[0]\n",
    "            y1 = b[1]\n",
    "            x2 = b[2]\n",
    "            y2 = b[3]\n",
    "            \n",
    "            \n",
    "            box = ET.SubElement(image, 'box')\n",
    "            box.attrib['label'] = \"person\"\n",
    "            box.attrib['occluded'] = \"0\"\n",
    "            box.attrib['xtl'] = str(float(x1))\n",
    "            box.attrib['ytl'] = str(float(y1))\n",
    "            box.attrib['xbr'] = str(float(x2))\n",
    "            box.attrib['ybr'] = str(float(y2))\n",
    "            \n",
    "            cv2.rectangle(orig_frame, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "            \n",
    "        xmlRoot.append(image)\n",
    "        cv2.imshow('person_frame', orig_frame)\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "    COUNT_ID += 1\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4adc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indent(xmlRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998e9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.write(config.PERSON_ANNOTATION_XML_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadbd97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:30:53.422873Z",
     "start_time": "2021-05-24T05:30:53.389865Z"
    }
   },
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IENetwork,IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd259f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:03.105979Z",
     "start_time": "2021-05-24T05:32:03.099488Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_xml_file = '/home/acer/Downloads/frozen_inference_graph_faster_rcnn_19/frozen_inference_graph_faster_rcnn_19.xml'\n",
    "path_to_bin_file = '/home/acer/Downloads/frozen_inference_graph_faster_rcnn_19/frozen_inference_graph_faster_rcnn_19.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821e1a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:03.567542Z",
     "start_time": "2021-05-24T05:32:03.334081Z"
    }
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "net = ie.read_network(model=path_to_xml_file, weights=path_to_bin_file)\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\", num_requests=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035f2f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:03.583857Z",
     "start_time": "2021-05-24T05:32:03.581552Z"
    }
   },
   "outputs": [],
   "source": [
    "input_blob = next(iter(net.input_info))\n",
    "out_blob = list(net.outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f13f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:03.941896Z",
     "start_time": "2021-05-24T05:32:03.938083Z"
    }
   },
   "outputs": [],
   "source": [
    "blob_shape = net.input_info[input_blob].tensor_desc.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faec3d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:04.208717Z",
     "start_time": "2021-05-24T05:32:04.202004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839c077b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:04.495650Z",
     "start_time": "2021-05-24T05:32:04.490634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NC'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.input_info[input_blob].tensor_desc.layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "724d5265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:04.884871Z",
     "start_time": "2021-05-24T05:32:04.880118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_info'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8668620f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T05:32:05.135213Z",
     "start_time": "2021-05-24T05:32:05.128428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detection_output']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f6cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
