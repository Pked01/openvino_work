{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T09:44:53.505842Z",
     "iopub.status.busy": "2021-06-16T09:44:53.505406Z",
     "iopub.status.idle": "2021-06-16T09:44:53.804613Z",
     "shell.execute_reply": "2021-06-16T09:44:53.803898Z",
     "shell.execute_reply.started": "2021-06-16T09:44:53.505796Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os,cv2,pickle,io,PIL,glob,json,itertools,functools,random\n",
    "import numpy as np\n",
    "import IPython.display as Disp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(\"/media/prateek/shared_space/useful_vids/person_dataset/CVAT/36/video_1.mp4\")\n",
    "\n",
    "# for i in range(25849):\n",
    "#     ret,frame = cap.read()\n",
    "#     cv2.imwrite(\"/media/prateek/shared_space/useful_vids/person_dataset/CVAT/36/images/frame_\"+str(i).zfill(6)+\".jpg\",frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A . Steps to create intermediate format pickle file\n",
    "1. Create saving folder of the data,  name this **saved_path** this folder will hold intermediate pickle file for annotation.\n",
    "2. Get the annnotation source files from the CVAT, pass the file path to variable tree\n",
    "3. Get the path of source images folder on the local machine, This path is required as  annotations might have been done on some other machine, we need exact location of images in the final annotation format\n",
    "5. This code will convert CVAT xml to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T10:42:57.904860Z",
     "iopub.status.busy": "2021-06-16T10:42:57.904629Z",
     "iopub.status.idle": "2021-06-16T10:42:57.908513Z",
     "shell.execute_reply": "2021-06-16T10:42:57.908059Z",
     "shell.execute_reply.started": "2021-06-16T10:42:57.904841Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def resolution_filter( bbox ,img, threshold = .2):\n",
    "    \"\"\"\n",
    "    given a bbox this function check the area occupied by a particular bbox and filter it accordingly\n",
    "    True :  means image resolution is upto mark\n",
    "    \"\"\"\n",
    "    resolution = ((bbox[3]-bbox[1])*(bbox[2]-bbox[0])/ (img.shape[0]*img.shape[1]))\n",
    "    print(resolution)\n",
    "    if resolution < threshold:\n",
    "        return False\n",
    "    return True\n",
    "        \n",
    "    \n",
    "def aspect_ratio_filter(bbox, filter_ratio=.3):\n",
    "    \"\"\"\n",
    "    aspect ratio = width/height < filter_ratio\n",
    "    True :  means aspect ratio is upto mark\n",
    "    filter ratio 1 means only cases where width is equal to height are allowed\n",
    "    \"\"\"\n",
    "    aspect_ratio  = (bbox[2]-bbox[0])/(bbox[3]-bbox[1])\n",
    "    print(aspect_ratio)\n",
    "    if  aspect_ratio > filter_ratio:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T10:12:07.505472Z",
     "iopub.status.busy": "2021-06-16T10:12:07.505270Z",
     "iopub.status.idle": "2021-06-16T10:12:07.512763Z",
     "shell.execute_reply": "2021-06-16T10:12:07.512188Z",
     "shell.execute_reply.started": "2021-06-16T10:12:07.505420Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6613861386138614"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bbox[2]-bbox[0])/(bbox[3]-bbox[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T10:45:31.330853Z",
     "iopub.status.busy": "2021-06-16T10:45:31.330596Z",
     "iopub.status.idle": "2021-06-16T10:48:46.411505Z",
     "shell.execute_reply": "2021-06-16T10:48:46.410925Z",
     "shell.execute_reply.started": "2021-06-16T10:45:31.330824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27353817654639173\n",
      "0.43007518796992483\n",
      "0.00939743648748159\n",
      "0.4462809917355372\n",
      "0.003963779455081001\n",
      "0.005436533505154639\n",
      "0.003594152706185567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = []\n",
    "plot = True\n",
    "apply_filter = True\n",
    "saved_path = \"/home/prateek/shared_space/DATA_N_MODELS/useful_vids/ANPR/\"\n",
    "tree = ET.parse('/home/prateek/shared_space/DATA_N_MODELS/useful_vids/ANPR/labels.xml')\n",
    "root = tree.getroot()\n",
    "for idx1,child in enumerate(root):\n",
    "    \n",
    "#     if idx1%10!=0:\n",
    "#         continue\n",
    "        \n",
    "    Disp.clear_output(wait=True)\n",
    "    if len(child.attrib)>0:\n",
    "        im = {}\n",
    "        im[\"im_path\"] =  saved_path+\"data/\"+child.attrib[\"name\"].replace(\"-2\",\"\")#.replace(\"Notebooks/UTCL/2021_01_07/HOT_MATERIAL_SUIT/\",\"/media/prateek/shared_space/useful_vids/person_dataset/CVAT/43/HOT_MATERIAL_SUIT/\")\n",
    "        if not os.path.exists(im[\"im_path\"]):\n",
    "            print( im[\"im_path\"])\n",
    "            continue\n",
    "        im[\"width\"] = int(child.attrib[\"width\"])\n",
    "        im[\"height\"] = int(child.attrib[\"height\"])\n",
    "        box = child.getchildren() \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for idx2,b in enumerate(box) :\n",
    "            if len(b.attrib)>0 and b.attrib[\"label\"]==\"Person\":### person label filtering\n",
    "                bbox = [float(b.attrib[\"xtl\"]),float(b.attrib[\"ytl\"]),float(b.attrib[\"xbr\"]),float(b.attrib[\"ybr\"])]\n",
    "                boxes.append(bbox)\n",
    "                labels.append(b.attrib[\"label\"])\n",
    "                if plot:\n",
    "                    img = cv2.imread(im[\"im_path\"])\n",
    "                    \n",
    "                    color = (0,255,0)\n",
    "                    if apply_filter:\n",
    "                        if (not resolution_filter(bbox,img,.004)) or (not aspect_ratio_filter(bbox,1)):\n",
    "                            color = (0,0,255)\n",
    "                    cv2.rectangle(img,(int(float(b.attrib[\"xtl\"])),int(float(b.attrib[\"ytl\"]))),(int(float(b.attrib[\"xbr\"])),int(float(b.attrib[\"ybr\"]))),color,1)\n",
    "                    cv2.imshow(\"preview\",img)\n",
    "                    k = cv2.waitKey(0)\n",
    "                    if k==ord('q'):\n",
    "                        plot=False\n",
    "                        \n",
    "        im[\"bbox\"] = boxes\n",
    "        im[\"labels\"] = labels\n",
    "        res.append(im)\n",
    "cv2.destroyAllWindows()\n",
    "pickle.dump(res,open(saved_path+\"cvat_xml.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Steps to create COCO dataset\n",
    "1. In step A multiple dataset pickle file will be developed\n",
    "2. In this step all the dataset annotation will be combined first and then converted to desired coco dataset format\n",
    "3. For training we need to partition dataset into 2 buckets of training and test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T11:05:46.572772Z",
     "iopub.status.busy": "2021-06-16T11:05:46.572260Z",
     "iopub.status.idle": "2021-06-16T11:05:47.291693Z",
     "shell.execute_reply": "2021-06-16T11:05:47.291312Z",
     "shell.execute_reply.started": "2021-06-16T11:05:46.572721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44286"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res_df = pd.DataFrame(res)\n",
    "\n",
    "# uniq_labels = np.unique(functools.reduce(lambda a,b : a+b,[i['labels'] for i in res]))\n",
    "\n",
    "# uniq_images = np.unique(res_df.im_path)\n",
    "\n",
    "comb_res = []\n",
    "for i in [3,6,7,9,10,36,39,42,43]: ## all pickle filename will be loaded here\n",
    "    res = pickle.load(open(\"/media/prateek/PK_HDD/prateek_space_penD/dataset/person_detection/CVAT/\"+str(i)+\"/cvat_xml.pickle\",\"rb\"))\n",
    "    comb_res = comb_res+ res\n",
    "\n",
    "len(comb_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below step is not compulsory but generally suggested to partition dataset into train and test set for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T11:14:41.892914Z",
     "iopub.status.busy": "2021-06-16T11:14:41.892760Z",
     "iopub.status.idle": "2021-06-16T11:14:41.910914Z",
     "shell.execute_reply": "2021-06-16T11:14:41.910421Z",
     "shell.execute_reply.started": "2021-06-16T11:14:41.892897Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ratio = .8\n",
    "random.shuffle(comb_res)\n",
    "train_res = comb_res[:int(train_ratio*len(comb_res))]\n",
    "val_res = comb_res[:int((1-train_ratio)*len(comb_res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T11:14:44.971654Z",
     "iopub.status.busy": "2021-06-16T11:14:44.971015Z",
     "iopub.status.idle": "2021-06-16T11:14:44.984733Z",
     "shell.execute_reply": "2021-06-16T11:14:44.982514Z",
     "shell.execute_reply.started": "2021-06-16T11:14:44.971580Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### support functions\n",
    "def xy2wh(bbox):\n",
    "    \"\"\"\n",
    "    converting \n",
    "    \"\"\"\n",
    "    return [bbox[0],bbox[1], bbox[2]-bbox[0],bbox[3]-bbox[1]]\n",
    "\n",
    "\n",
    "def bbox2poly(bbox):\n",
    "    x,y,w,h = [bbox[0],bbox[1], bbox[2]-bbox[0],bbox[3]-bbox[1]]    \n",
    "    return [bbox[0],bbox[1],x+w,y, x+w, y+h, x, y+h]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conversion to coco dataset\n",
    "1. pickle files developed above can be combined(if multiple dataset) and passed  below to variable **res**\n",
    "2. set file path of annotation json file you want to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T11:15:13.781418Z",
     "iopub.status.busy": "2021-06-16T11:15:13.781277Z",
     "iopub.status.idle": "2021-06-16T11:15:32.315271Z",
     "shell.execute_reply": "2021-06-16T11:15:32.314868Z",
     "shell.execute_reply.started": "2021-06-16T11:15:13.781402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = train_res # change this line \n",
    "annotation_json_file_path = \"/media/prateek/PK_HDD/prateek_space_penD/dataset/person_detection/CVAT/combined_train_coco.json\"\n",
    "# res_df = pd.DataFrame(res)\n",
    "images = []\n",
    "categories = []\n",
    "annotations = []\n",
    "licenses = []\n",
    "info = {}\n",
    "\n",
    "\n",
    "\n",
    "license = {}\n",
    "license[\"id\"] = \"\"\n",
    "license[\"name\"] = \"\"\n",
    "license[\"url\"] = \"\"\n",
    "licenses.append(license)\n",
    "\n",
    "info = {}\n",
    "info[\"contributor\"] = \"\"\n",
    "info[\"date_created\"] = \"\"\n",
    "info[\"description\"] = \"\"\n",
    "info[\"url\"] = \"\"\n",
    "info[\"version\"] = \"\"\n",
    "info[\"year\"] = \"\"\n",
    "\n",
    "uniq_labels = np.unique(functools.reduce(lambda a,b : a+b,[i['labels'] for i in res]))\n",
    "lbl2idx = dict(zip(uniq_labels,list(range(1,len(uniq_labels)+1))))\n",
    "\n",
    "\n",
    "for label, index in lbl2idx.items():\n",
    "    category = {}\n",
    "    category[\"name\"] = label\n",
    "    category[\"id\"] = index   \n",
    "    category[\"supercategory\"] = None\n",
    "    categories.append(category)\n",
    "\n",
    "\n",
    "annotation_id = 1 \n",
    "for idx,result in enumerate(res):\n",
    "    image = {}\n",
    "    image[\"file_name\"] = result['im_path']\n",
    "    image[\"width\"] = result['width']\n",
    "    image[\"height\"] = result['height']\n",
    "    image[\"coco_url\"] = \"\"\n",
    "    image[\"flickr_url\"] = \"\"\n",
    "    image[\"date_captured\"] = 0\n",
    "    image[\"license\"] = 0\n",
    "    image[\"id\"] = idx # same as image_id in annotations\n",
    "    images.append(image)\n",
    "    for idx1,b in enumerate(result[\"bbox\"]):\n",
    "        x,y,w,h = xy2wh(b)\n",
    "        annotation = {}\n",
    "        annotation[\"image_id\"] = idx  # same as id in images\n",
    "        annotation[\"id\"] = annotation_id\n",
    "        annotation[\"bbox\"] = [x,y,w,h]\n",
    "        annotation[\"segmentation\"] = bbox2poly(b)\n",
    "        annotation[\"area\"] = w*h\n",
    "        annotation[\"iscrowd\"] = 0\n",
    "        annotation[\"category_id\"] = lbl2idx[result[\"labels\"][idx1]]\n",
    "        annotation_id+=1\n",
    "        annotations.append(annotation)\n",
    "\n",
    "data_coco = {}\n",
    "data_coco[\"images\"] = images\n",
    "data_coco[\"categories\"] = categories\n",
    "data_coco[\"annotations\"] = annotations\n",
    "data_coco[\"info\"] = info\n",
    "data_coco[\"licenses\"] = licenses\n",
    "\n",
    "json.dump(data_coco, open(annotation_json_file_path, \"w\"), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_p38",
   "language": "python",
   "name": "cv_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
