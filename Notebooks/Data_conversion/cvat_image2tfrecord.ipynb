{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T06:23:16.673540Z",
     "iopub.status.busy": "2021-05-05T06:23:16.673389Z",
     "iopub.status.idle": "2021-05-05T06:23:16.676296Z",
     "shell.execute_reply": "2021-05-05T06:23:16.675891Z",
     "shell.execute_reply.started": "2021-05-05T06:23:16.673524Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os,cv2,pickle,io,PIL,ast,shutil,functools,json\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import IPython.display as Disp\n",
    "\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-04T09:37:57.206715Z",
     "iopub.status.idle": "2021-05-04T09:37:57.206888Z"
    }
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "tree = ET.parse(\"tfrecord/TASK86/2021_04_22_white_helmet_veraval.xml\")\n",
    "root = tree.getroot()\n",
    "for child in root:\n",
    "    Disp.clear_output(wait=True)\n",
    "    if len(child.attrib)>0:\n",
    "        im = {}\n",
    "        im[\"im_path\"] = \"/home/ubuntu/mount/\"+child.attrib[\"name\"]\n",
    "        if not os.path.exists(im[\"im_path\"]):\n",
    "            print( im[\"im_path\"])\n",
    "        im[\"width\"] = int(child.attrib[\"width\"])\n",
    "        im[\"height\"] = int(child.attrib[\"height\"])\n",
    "        box = child.getchildren() \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for b in box :\n",
    "            if len(b.attrib)>0: #and b.attrib[\"label\"]==\"person\":### person label filtering\n",
    "                boxes.append([float(b.attrib[\"xtl\"]),float(b.attrib[\"ytl\"]),float(b.attrib[\"xbr\"]),float(b.attrib[\"ybr\"])])\n",
    "                label = b.attrib[\"label\"]\n",
    "                if b.attrib[\"label\"]=='white_shirt':\n",
    "                    label = 'no_vest'\n",
    "                if b.attrib[\"label\"]=='dark_shirt':\n",
    "                    label = 'worker'\n",
    "                  \n",
    "                labels.append(label)\n",
    "        im[\"bbox\"] = boxes\n",
    "        im[\"labels\"] = labels\n",
    "        res.append(im)\n",
    "\n",
    "# pickle.dump(res,open(folder_path+\"cvat_xml.pickle\",\"wb\"))\n",
    "os.makedirs(\"tfrecord/TASK86/\",exist_ok=True)\n",
    "pickle.dump(res,open(\"tfrecord/TASK86/cvat_xml.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-04T09:37:58.628093Z",
     "iopub.status.busy": "2021-05-04T09:37:58.627422Z",
     "iopub.status.idle": "2021-05-04T09:38:00.397561Z",
     "shell.execute_reply": "2021-05-04T09:38:00.397097Z",
     "shell.execute_reply.started": "2021-05-04T09:37:58.628018Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.sys.path.append(\"/home/ubuntu/mount/Notebooks/models/research/\")\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "import tensorflow as tf\n",
    "\n",
    "def image_tfrecord(res,label_dict,min_resolution_thresh=None):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "        res\n",
    "        \n",
    "        {'im_path': '/home/ubuntu/mount/Notebooks/abg/helmet_n_vest/person_detection/2021_04_22_white_helmet_veraval/white_helmet_dataset_cropped/image_00002.jpg',\n",
    "          'width': 180,\n",
    "          'height': 354,\n",
    "          'bbox': [[18.1, 65.75, 118.0, 213.0], [45.83, 10.0, 112.0, 92.19]],\n",
    "          'labels': ['worker', 'no_helmet']}\n",
    "\n",
    "            im_path : absolute image_path\n",
    "            width : width of image\n",
    "            height : height of image\n",
    "            bbox : list of bounding box in image\n",
    "        label_dict : dictionary for labels\n",
    "        min_resolution_thresh : image should be bigger than some resolution\n",
    "    Returns :\n",
    "        returns tf train example\n",
    "    \"\"\"\n",
    "    image_path = res[\"im_path\"]\n",
    "    with tf.gfile.GFile(image_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    width = int(res[\"width\"])\n",
    "    height = int(res[\"height\"])\n",
    "    if min_resolution_thresh is not None:\n",
    "        if width*height<min_resolution_thresh:\n",
    "            print(\"very less resolution\")\n",
    "            return None\n",
    "    \n",
    "#     print(width,height)\n",
    "    bboxes = np.array(res[\"bbox\"])\n",
    "    xmin = np.clip(bboxes[:,0]/width,0,1).astype(float).tolist()\n",
    "    ymin = np.clip(bboxes[:,1]/height,0,1).astype(float).tolist()\n",
    "    xmax = np.clip(bboxes[:,2]/width,0,1).astype(float).tolist()\n",
    "    ymax = np.clip(bboxes[:,3]/height,0,1).astype(float).tolist()\n",
    "#     print(xmin,ymin,xmax,ymax)\n",
    "    if max([max(xmin),max(ymin),max(xmax),max(ymax)])>1:\n",
    "        print(xmin,ymin,xmax,ymax)\n",
    "        print(\"incorrect bbox\")\n",
    "        return None\n",
    "\n",
    "    classes_text = [label.encode('utf8') for label in res[\"labels\"] ]\n",
    "    classes = [label_dict[label] for label in res[\"labels\"]]\n",
    "    \n",
    "\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          image_path.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          image_path.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "\n",
    "  }))\n",
    "    return example\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-04T09:38:00.619691Z",
     "iopub.status.busy": "2021-05-04T09:38:00.619461Z",
     "iopub.status.idle": "2021-05-04T09:38:00.912798Z",
     "shell.execute_reply": "2021-05-04T09:38:00.912304Z",
     "shell.execute_reply.started": "2021-05-04T09:38:00.619665Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/media/prateek/shared_space/DATA_N_MODELS/useful_vids/helmet_vest/old_helmet_vest_crop_data/comb_df_cleaned.csv\")\n",
    "df.helmet_coords = df.helmet_coords.apply(lambda x : ast.literal_eval(x))\n",
    "df.vest_coords = df.vest_coords.apply(lambda x : ast.literal_eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-04T09:38:01.641908Z",
     "iopub.status.busy": "2021-05-04T09:38:01.641189Z",
     "iopub.status.idle": "2021-05-04T09:38:01.650611Z",
     "shell.execute_reply": "2021-05-04T09:38:01.648580Z",
     "shell.execute_reply.started": "2021-05-04T09:38:01.641832Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict =     {'helmet':1,\n",
    "    'no_helmet':2,\n",
    " 'vest':3,\n",
    " 'no_vest':4,\n",
    "'worker':5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T05:54:49.672043Z",
     "iopub.status.busy": "2021-05-05T05:54:49.671563Z",
     "iopub.status.idle": "2021-05-05T05:55:08.673888Z",
     "shell.execute_reply": "2021-05-05T05:55:08.673521Z",
     "shell.execute_reply.started": "2021-05-05T05:54:49.672027Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(\"/media/prateek/shared_space/DATA_N_MODELS/useful_vids/helmet_vest/old_helmet_vest_crop_data/combined_df_cleaned.tfrecord\")\n",
    "# res = []\n",
    "for idx,row in df.iterrows():\n",
    "    r1 = {}\n",
    "    r1[\"im_path\"] = os.path.join(\"/media/prateek/shared_space/DATA_N_MODELS/useful_vids/helmet_vest/old_helmet_vest_crop_data\",\"/\".join((row[\"filename\"]).split(\"/\")[-2:]))\n",
    "    b1 = list(row[\"helmet_coords\"])\n",
    "    b2 = list(row[\"vest_coords\"])\n",
    "    \n",
    "    r1[\"bbox\"] = [b1,b2]\n",
    "    l1 = row[\"helmet_label\"]\n",
    "    l2 = row[\"vest_label\"]\n",
    "    if l1==\"sardar\":\n",
    "        l1=\"helmet\"\n",
    "    r1[\"labels\"] = [l1,l2]\n",
    "    r1[\"width\"],r1[\"height\"] = imagesize.get(r1[\"im_path\"])\n",
    "#     res.append(r1)\n",
    "    try:\n",
    "        tf_example = image_tfrecord(r1,label_dict)\n",
    "    except Exception as e:\n",
    "            print(e)\n",
    "    if tf_example is not None:\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "writer.close()\n",
    "    \n",
    "# pickle.dump(res,open(\"/media/prateek/shared_space/DATA_N_MODELS/useful_vids/helmet_vest/old_helmet_vest_crop_data/combined_df_cleaned_cvat_xml.pickle\",\"wb\")) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T06:23:23.656473Z",
     "iopub.status.busy": "2021-05-05T06:23:23.656072Z",
     "iopub.status.idle": "2021-05-05T06:23:41.571032Z",
     "shell.execute_reply": "2021-05-05T06:23:41.570530Z",
     "shell.execute_reply.started": "2021-05-05T06:23:23.656428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def xy2wh(bbox):\n",
    "    \"\"\"\n",
    "    converting \n",
    "    \"\"\"\n",
    "    return [bbox[0],bbox[1], bbox[2]-bbox[0],bbox[3]-bbox[1]]\n",
    "\n",
    "\n",
    "def bbox2poly(bbox):\n",
    "    x,y,w,h = [bbox[0],bbox[1], bbox[2]-bbox[0],bbox[3]-bbox[1]]    \n",
    "    return [bbox[0],bbox[1],x+w,y, x+w, y+h, x, y+h]\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "#      res   {'im_path': '/home/ubuntu/mount/Notebooks/abg/helmet_n_vest/person_detection/2021_04_22_white_helmet_veraval/white_helmet_dataset_cropped/image_00002.jpg',\n",
    "#           'width': 180,\n",
    "#           'height': 354,\n",
    "#           'bbox': [[18.1, 65.75, 118.0, 213.0], [45.83, 10.0, 112.0, 92.19]],\n",
    "#           'labels': ['worker', 'no_helmet']}\n",
    "# res = val_res # change this line \n",
    "res = res\n",
    "\n",
    "# res_df = pd.DataFrame(res)\n",
    "images = []\n",
    "categories = []\n",
    "annotations = []\n",
    "licenses = []\n",
    "info = {}\n",
    "\n",
    "\n",
    "save_path = \"/media/prateek/shared_space/DATA_N_MODELS/tfrecords/coco_dataset/taloja_crop_data/\"\n",
    "save_img = True\n",
    "if save_img:\n",
    "    os.makedirs(os.path.join(save_path,\"annotations\"),exist_ok=True)\n",
    "    os.makedirs(os.path.join(save_path,\"images\"),exist_ok=True)\n",
    "\n",
    "\n",
    "license = {}\n",
    "license[\"id\"] = \"\"\n",
    "license[\"name\"] = \"\"\n",
    "license[\"url\"] = \"\"\n",
    "licenses.append(license)\n",
    "\n",
    "info = {}\n",
    "info[\"contributor\"] = \"\"\n",
    "info[\"date_created\"] = \"\"\n",
    "info[\"description\"] = \"\"\n",
    "info[\"url\"] = \"\"\n",
    "info[\"version\"] = \"\"\n",
    "info[\"year\"] = \"\"\n",
    "\n",
    "uniq_labels = np.unique(functools.reduce(lambda a,b : a+b,[i['labels'] for i in res]))\n",
    "lbl2idx = dict(zip(uniq_labels,list(range(1,len(uniq_labels)+1))))\n",
    "\n",
    "\n",
    "for label, index in lbl2idx.items():\n",
    "    category = {}\n",
    "    category[\"name\"] = label\n",
    "    category[\"id\"] = index   \n",
    "    category[\"supercategory\"] = None\n",
    "    categories.append(category)\n",
    "\n",
    "\n",
    "annotation_id = 1 \n",
    "for idx,result in enumerate(res):\n",
    "    image = {}\n",
    "    image[\"file_name\"] = result['im_path']\n",
    "    if save_img:\n",
    "        img = shutil.copy2(result['im_path'],os.path.join(save_path,\"images\",os.path.basename(result['im_path'])))\n",
    "        image[\"file_name\"] = os.path.basename(result['im_path'])\n",
    "                           \n",
    "    image[\"width\"] = result['width']\n",
    "    image[\"height\"] = result['height']\n",
    "    image[\"coco_url\"] = \"\"\n",
    "    image[\"flickr_url\"] = \"\"\n",
    "    image[\"date_captured\"] = 0\n",
    "    image[\"license\"] = 0\n",
    "    image[\"id\"] = idx # same as image_id in annotations\n",
    "    images.append(image)\n",
    "    for idx1,b in enumerate(result[\"bbox\"]):\n",
    "        x,y,w,h = xy2wh(b)\n",
    "        annotation = {}\n",
    "        annotation[\"image_id\"] = idx # same as id in images\n",
    "        annotation[\"id\"] = annotation_id\n",
    "        annotation[\"bbox\"] = [x,y,w,h]\n",
    "        annotation[\"segmentation\"] = bbox2poly(b)\n",
    "        annotation[\"area\"] = w*h\n",
    "        annotation[\"iscrowd\"] = 0\n",
    "        annotation[\"category_id\"] = lbl2idx[result[\"labels\"][idx1]]\n",
    "        annotation_id+=1\n",
    "        annotations.append(annotation)\n",
    "\n",
    "data_coco = {}\n",
    "data_coco[\"images\"] = images\n",
    "data_coco[\"categories\"] = categories\n",
    "data_coco[\"annotations\"] = annotations\n",
    "data_coco[\"info\"] = info\n",
    "data_coco[\"licenses\"] = licenses\n",
    "\n",
    "json.dump(data_coco, open(os.path.join(save_path,\"annotations\",\"instances_default.json\"), \"w\"), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.python_io.TFRecordWriter(\"tfrecord/TASK86/annotation.tfrecord\")\n",
    "tf_example = None\n",
    "for r1 in res:\n",
    "        try:\n",
    "            tf_example = image_tfrecord(r1,label_dict)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        if tf_example is not None:\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "def split_dataset(dataset: tf.data.Dataset, \n",
    "                  dataset_size: int, \n",
    "                  train_ratio: float, \n",
    "                  validation_ratio: float) -> Tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]:\n",
    "    assert (train_ratio + validation_ratio) <= 1\n",
    "\n",
    "    train_count = int(dataset_size * train_ratio)\n",
    "    validation_count = int(dataset_size * validation_ratio)\n",
    "    test_count = dataset_size - (train_count + validation_count)\n",
    "\n",
    "    dataset = dataset.shuffle(dataset_size)\n",
    "\n",
    "    train_dataset = dataset.take(train_count)\n",
    "    validation_dataset = dataset.skip(train_count).take(validation_count)\n",
    "    test_dataset = dataset.skip(validation_count + train_count).take(test_count)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_dataset = tf.data.TFRecordDataset([\"tfrecord/TASK86/annotation.tfrecord\"\n",
    "                                           ])\n",
    "#                                             \"tfrecords/negative_files_AFR.tfrecord\"])\n",
    "#                                             \"tfrecords/TASK27/annotation.tfrecord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1970"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## total dataset\n",
    "sum(1 for _ in tfrecord_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validation,test = split_dataset(tfrecord_dataset,1970,.8,.2)#test will be zero\n",
    "\n",
    "train_path = './train.tfrecord'\n",
    "with tf.io.TFRecordWriter(train_path) as writer:\n",
    "    for i in train:\n",
    "        writer.write(i.numpy())\n",
    "        \n",
    "        \n",
    "validation_path = './validation.tfrecord'\n",
    "with tf.io.TFRecordWriter(validation_path) as writer:\n",
    "    for i in validation:\n",
    "        writer.write(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 tfviewer.py /home/computer_vision/Downloads/Notebooks/abg/FIRE/tfrecords/TASK17/annotation.tfrecord   --labels-to-highlight='fire;smoke;neutral'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_1",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
