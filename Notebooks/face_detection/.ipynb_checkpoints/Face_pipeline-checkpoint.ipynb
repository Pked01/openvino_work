{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:24:57.779655Z",
     "start_time": "2019-08-12T09:24:54.071121Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser, SUPPRESS\n",
    "import cv2,threading\n",
    "import time\n",
    "import logging as log\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "import numpy as np\n",
    "from multiprocessing import Process,Pool\n",
    "import shutil,pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:24:57.787071Z",
     "start_time": "2019-08-12T09:24:57.782070Z"
    }
   },
   "outputs": [],
   "source": [
    "m_fd = '../model_downloader/Retail/object_detection/face/sqnet1.0modif-ssd/0004/dldt/face-detection-retail-0004.xml'\n",
    "m_ag = '../model_downloader/Retail/object_attributes/age_gender/dldt/age-gender-recognition-retail-0013.xml'\n",
    "m_hp = '../model_downloader/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001.xml'\n",
    "m_em = '../model_downloader/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003.xml'\n",
    "m_freid = '../model_downloader/Retail/object_reidentification/face/mobilenet_based/dldt/face-reidentification-retail-0095.xml'\n",
    "channel = 'rtsp://admin:admin@123@10.10.12.14:554/Streaming/Channels/401/'\n",
    "cpu_extension = '../build_here/intel64/Release/lib/libcpu_extension.so'\n",
    "device = 'CPU'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:25:00.055245Z",
     "start_time": "2019-08-12T09:24:58.922323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plugin initialization for specified device and load extensions library if specified\n",
    "log.info(\"Initializing plugin for {} device...\".format('CPU'))\n",
    "plugin = IEPlugin(device='CPU')\n",
    "if cpu_extension and 'CPU' in device:\n",
    "    plugin.add_cpu_extension(cpu_extension)\n",
    "# Read IR\n",
    "log.info(\"Reading IR...\")\n",
    "m_fd_net = IENetwork(model=m_fd, weights=os.path.splitext(m_fd)[0] + \".bin\")\n",
    "m_ag_net = IENetwork(model=m_ag, weights=os.path.splitext(m_ag)[0] + \".bin\")\n",
    "m_hp_net = IENetwork(model=m_hp, weights=os.path.splitext(m_hp)[0] + \".bin\")\n",
    "m_em_net = IENetwork(model=m_em, weights=os.path.splitext(m_em)[0] + \".bin\")\n",
    "m_freid_net = IENetwork(model=m_freid, weights=os.path.splitext(m_freid)[0] + \".bin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:25:00.808327Z",
     "start_time": "2019-08-12T09:25:00.790734Z"
    }
   },
   "outputs": [],
   "source": [
    "if device == \"CPU\":\n",
    "    for net in [m_fd_net,m_ag_net,m_hp_net,m_em_net,m_freid_net]:\n",
    "        supported_layers = plugin.get_supported_layers(net)\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(plugin.device, ', '.join(not_supported_layers)))\n",
    "            log.error(\"Please try to specify cpu extensions library path in demo's command line parameters using -l \"\n",
    "                      \"or --cpu_extension command line argument\")\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:25:02.353376Z",
     "start_time": "2019-08-12T09:25:01.835717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 300 3 300\n",
      "1 62 3 62\n",
      "1 60 3 60\n",
      "1 64 3 64\n",
      "1 128 3 128\n"
     ]
    }
   ],
   "source": [
    "input_blob = []\n",
    "out_blob = []\n",
    "exec_net = []\n",
    "for i,net in enumerate([m_fd_net,m_ag_net,m_hp_net,m_em_net,m_freid_net]):\n",
    "    # assert len(net.inputs.keys()) == 1, \"Demo supports only single input topologies\"\n",
    "    # assert len(net.outputs) == 1, \"Demo supports only single output topologies\"\n",
    "    input_blob.append(next(iter(net.inputs)))\n",
    "    out_blob.append(next(iter(net.outputs)))\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    exec_net.append(plugin.load(network=net, num_requests=16))\n",
    "    # Read and pre-process input image\n",
    "    n, c, h, w = net.inputs[input_blob[i]].shape\n",
    "    print(n,h,c,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:25:03.431781Z",
     "start_time": "2019-08-12T09:25:03.426232Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_fd(input_frame,n=1,c=3,w=300,h=300,thresh=.1):\n",
    "    op_frame = cv2.resize(input_frame,(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) \n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    exec_net[0].start_async(request_id=1, inputs={input_blob[0]: op_frame})\n",
    "    if exec_net[0].requests[1].wait(-1)==0:\n",
    "        res = exec_net[0].requests[1].outputs[out_blob[0]]\n",
    "    res_filt =  res[np.where(res[:,:,:,2]>thresh)]\n",
    "    res_filt = res_filt[np.min(res_filt,axis=1)>=0]\n",
    "    return res_filt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T09:25:04.872678Z",
     "start_time": "2019-08-12T09:25:04.863212Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_ag(input_frame,bboxes,n=1,c=3,w=62,h=62):\n",
    "    \"\"\"\n",
    "    output : age/100\n",
    "    prob : [female, male]\n",
    "    \"\"\"\n",
    "    \n",
    "    res = []\n",
    "    faces = [cv2.resize(input_frame[b[1]:b[3],b[0]:b[2]],(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) for b in bboxes]\n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    [exec_net[1].start_async(request_id=cursor_id, inputs={input_blob[1]: face}) for cursor_id,face in enumerate(faces)]\n",
    "    for i in range(len(faces)):\n",
    "        if exec_net[1]. requests[i].wait(-1)==0:\n",
    "            res.append(exec_net[1].requests[i].outputs)\n",
    "    age = [int(i['age_conv3']*100) for i in res]\n",
    "    gender = [ 'Female' if i['prob'][0][0]>i['prob'][0][1] else 'Male' for i in res]\n",
    "    return list(zip(age,gender))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:29:53.103182Z",
     "start_time": "2019-08-11T13:29:53.010642Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_hp(input_frame,bboxes,n=1,c=3,w=60,h=60):\n",
    "    res = []\n",
    "    faces = [cv2.resize(input_frame[b[1]:b[3],b[0]:b[2]],(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) for b in bboxes]\n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    [exec_net[2].start_async(request_id=cursor_id, inputs={input_blob[2]: face}) for cursor_id,face in enumerate(faces)]\n",
    "    for i in range(len(faces)):\n",
    "        if exec_net[2].requests[i].wait(-1)==0:\n",
    "            res.append(exec_net[2].requests[i].outputs)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:29:53.197579Z",
     "start_time": "2019-08-11T13:29:53.105051Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_em(input_frame,bboxes,n=1,c=3,w=64,h=64):\n",
    "    \"\"\"\n",
    "    'neutral', 'happy', 'sad', 'surprise', 'anger'\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    faces = [cv2.resize(input_frame[b[1]:b[3],b[0]:b[2]],(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) for b in bboxes]\n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    [exec_net[3].start_async(request_id=cursor_id, inputs={input_blob[3]: face}) for cursor_id,face in enumerate(faces)]\n",
    "    for i in range(len(faces)):\n",
    "        if exec_net[3].requests[i].wait(-1)==0:\n",
    "            res.append(exec_net[3].requests[i].outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:29:53.315423Z",
     "start_time": "2019-08-11T13:29:53.199275Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_face_embedding(input_frame,bboxes,n=1,c=3,w=128,h=128):\n",
    "    res = []\n",
    "    faces = [cv2.resize(input_frame[b[1]:b[3],b[0]:b[2]],(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) for b in bboxes]\n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    [exec_net[4].start_async(request_id=cursor_id, inputs={input_blob[4]: face}) for cursor_id,face in enumerate(faces)]\n",
    "    for i in range(len(faces)):\n",
    "        if exec_net[4].requests[i].wait(-1)==0:\n",
    "            res.append(exec_net[4].requests[i].outputs)\n",
    "    return np.array([i['658'].flatten() for i in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:29:53.398840Z",
     "start_time": "2019-08-11T13:29:53.317193Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_file_path(source_dir,ext=('.jpg','.png','.jpeg')):\n",
    "    \"\"\"\n",
    "    all images with csv extension exist in set of dirs\n",
    "    \"\"\"\n",
    "    op =[]\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(ext):\n",
    "                \n",
    "                 op.append(os.path.join(os.path.abspath(root), file))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:33:37.889199Z",
     "start_time": "2019-08-11T13:33:37.878626Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_face_detection(train_data_location,thresh=.5):\n",
    "    \"\"\"\n",
    "    train_data is in format of person name as folder name and containing images\n",
    "    this function will return classifier and label_encoder\n",
    "    \n",
    "    \"\"\"\n",
    "    imgs = get_all_file_path(train_data_location)\n",
    "    labels = [os.path.basename(os.path.dirname(f)) for f in imgs]\n",
    "    embeddings = []\n",
    "    for f in imgs:\n",
    "        im = cv2.imread(f)\n",
    "        initial_h,initial_w = im.shape[:2]\n",
    "        while True:\n",
    "            res_filt = generate_fd(im,thresh=thresh)\n",
    "            bboxes = np.multiply([[initial_w,initial_h,initial_w,initial_h]],(res_filt[:,3:])).astype('int')\n",
    "            embedding = generate_face_embedding(im,bboxes)\n",
    "            if embedding.shape[0]>1:\n",
    "                thresh = thresh+.05\n",
    "            elif embedding.shape[0]==0:\n",
    "                thresh = thresh-.05\n",
    "            else:\n",
    "                embeddings.append(embedding)\n",
    "                break\n",
    "    embedding_array = np.concatenate(embeddings)\n",
    "    L_enc = LabelEncoder()\n",
    "    labels_enc = L_enc.fit_transform(labels)\n",
    "#     print(len(embeddings),embedding_array.shape,labels_enc.shape)\n",
    "    clf = LogisticRegression(n_jobs=-1,class_weight='balanced')\n",
    "    clf.fit(embedding_array,labels_enc)\n",
    "    pickle.dump(L_enc,open(os.path.join(train_data_location,'label_encoder.pickle'),'wb'))\n",
    "    pickle.dump(clf,open(os.path.join(train_data_location,'classifier.pickle'),'wb'))\n",
    "    return clf, L_enc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:33:38.670440Z",
     "start_time": "2019-08-11T13:33:38.658624Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_plot(in_frame,clf,L_enc,thresh = .2):\n",
    "    \"\"\"\n",
    "    input_frame\n",
    "    clf : classfier for face recognition\n",
    "    L_enc : label_encoder for face recognition\n",
    "    initial_h: initial_height of frame\n",
    "    initial_w : initial_width of frame\n",
    "    \"\"\"\n",
    "    ### all detect and plot should be called sequently \n",
    "    initial_h,initial_w = in_frame.shape[:2]\n",
    "    res_filt = generate_fd(frame,thresh=thresh)\n",
    "    bboxes = np.multiply([[initial_w,initial_h,initial_w,initial_h]],(res_filt[:,3:])).astype('int')\n",
    "    if len(bboxes)>0:\n",
    "        names = L_enc.inverse_transform(clf.predict(generate_face_embedding(frame,bboxes)))\n",
    "        age_gender = generate_ag(frame,bboxes)\n",
    "        for name,a_g,b in zip(names,age_gender,bboxes):\n",
    "            if a_g[1]=='Female':\n",
    "                pink = (193,182,255)\n",
    "                deep_pink = (193,20,255)\n",
    "                caption = name.upper()+'('+str(a_g[0]) + ' , '+a_g[1]+')'\n",
    "                cv2.rectangle(in_frame, (b[0], b[1]), (b[2], b[3]), pink, 2)\n",
    "                cv2.putText(frame, caption,\n",
    "                                    (b[0]-10, b[1] - 10),cv2.FONT_HERSHEY_COMPLEX, 0.6, deep_pink, 1)\n",
    "            else:\n",
    "                blue = (255,0,0)\n",
    "                deep_blue = (200,0,0)\n",
    "                caption = name.upper()+'('+str(a_g[0]) + ' , '+a_g[1]+')'\n",
    "                cv2.rectangle(in_frame, (b[0], b[1]), (b[2], b[3]), blue, 2)\n",
    "                cv2.putText(frame, caption,\n",
    "                                    (b[0]-10, b[1] - 10),cv2.FONT_HERSHEY_COMPLEX, 0.6, deep_blue, 1)\n",
    "    return frame\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:33:46.122438Z",
     "start_time": "2019-08-11T13:33:46.112292Z"
    }
   },
   "outputs": [],
   "source": [
    "Force_retraining = False\n",
    "image_location = '../face_images/consolidated_data/'\n",
    "if (os.path.isfile(os.path.join(image_location,'classifier.pickle')) & os.path.isfile(os.path.join(image_location,'label_encoder.pickle'))& (not Force_retraining)):\n",
    "    clf = pickle.load(open(os.path.join(image_location,'classifier.pickle'),'rb'))\n",
    "    L_enc = pickle.load(open(os.path.join(image_location,'label_encoder.pickle'),'rb'))\n",
    "else:\n",
    "    clf,L_enc = train_face_detection('../face_images/consolidated_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T13:33:47.881874Z",
     "start_time": "2019-08-11T13:33:47.878973Z"
    }
   },
   "outputs": [],
   "source": [
    "channel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T07:40:05.527618Z",
     "start_time": "2019-08-12T07:39:23.604573Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Detection Results\",cv2.WINDOW_NORMAL)\n",
    "fd_thresh = .4\n",
    "# if labels:\n",
    "#     with open(labels, 'r') as f:\n",
    "#         labels_map = [x.strip() for x in f]\n",
    "# else:\n",
    "#     labels_map = None\n",
    "\n",
    "cap = cv2.VideoCapture(channel)\n",
    "retry_connect = 10\n",
    "cur_request_id = 0\n",
    "fps_fd = []\n",
    "net_fps = []\n",
    "while (cap.isOpened()):\n",
    "    fps_fd = fps_fd[-100:]\n",
    "    initial_w = cap.get(3)\n",
    "    initial_h = cap.get(4)\n",
    "    inf_start_fd = time.time()\n",
    "    ret,frame  = cap.read()\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(channel)\n",
    "        retry_connect-=1\n",
    "        if retry_connect<0:\n",
    "            break\n",
    "    frame = generate_plot(frame,clf,L_enc,thresh=.3)\n",
    "    det_time_fd = time.time()- inf_start_fd\n",
    "\n",
    "    fps_fd.append(1/det_time_fd)\n",
    "    cv2.putText(frame, \"Inference FPS Face detection: {:.3f} \".format(np.mean(fps_fd)), (10, int(initial_h - 50)), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "            (10, 10, 200), 1)\n",
    "    net_fps.append(np.mean(fps_fd))\n",
    "    \n",
    "    #\n",
    "    render_start = time.time()\n",
    "    cv2.imshow(\"Detection Results\", frame)\n",
    "    render_end = time.time()\n",
    "    render_time = render_end - render_start\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
