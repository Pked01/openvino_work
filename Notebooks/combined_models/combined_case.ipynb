{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os,time,re\n",
    "os.sys.path.append('/home/prateek/shared_space/Notebooks/abg/openvino/Notebooks/utilities/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import IPython.display as Disp\n",
    "import support_utility_openvino\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon,Point\n",
    "import ipywidgets as widgets\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_vehicle_model_path = \"/home/prateek/prateek_space/intel_model_dump/intel/pedestrian-and-vehicle-detector-adas-0001/INT8/pedestrian-and-vehicle-detector-adas-0001.xml\"\n",
    "helmet_vest_model_path = \"/media/prateek/prateek_space/model_files/openvino_model/2020_02_04_only_person_model/converted_1/frozen_inference_graph.xml\"#ssd inception net model\n",
    "attr_model_path = \"/home/prateek/prateek_space/intel_model_dump/intel/vehicle-attributes-recognition-barrier-0039/INT8/vehicle-attributes-recognition-barrier-0039.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_support = support_utility_openvino.create_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_requests = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices :  ['CPU', 'GNA', 'GPU']\n",
      "model inputs : dict_keys(['data'])\n",
      "model outputs :  dict_keys(['detection_out'])\n"
     ]
    }
   ],
   "source": [
    "person_vehicle_model = support_utility_openvino.async_infer(num_requests=num_requests)\n",
    "person_vehicle_model.load_model(model_path=person_vehicle_model_path,device=\"MULTI:CPU,GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices :  ['CPU', 'GNA', 'GPU']\n",
      "model inputs : dict_keys(['image_tensor'])\n",
      "model outputs :  dict_keys(['DetectionOutput'])\n"
     ]
    }
   ],
   "source": [
    "helmet_vest_model = support_utility_openvino.async_infer(num_requests=num_requests,ie_network=person_vehicle_model.ie)\n",
    "helmet_vest_model.load_model(model_path=helmet_vest_model_path,device=\"MULTI:CPU,GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Devices :  ['CPU', 'GNA', 'GPU']\n",
      "model inputs : dict_keys(['input'])\n",
      "model outputs :  dict_keys(['color', 'type'])\n"
     ]
    }
   ],
   "source": [
    "attr_model = support_utility_openvino.async_infer(num_requests=num_requests,ie_network=person_vehicle_model.ie)\n",
    "attr_model.load_model(model_path=attr_model_path,device=\"MULTI:CPU,GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_intersection_shapely(polygon, point):\n",
    "    \"\"\"\n",
    "    polygon : set of points for polygon[[x1,y1],[x2,y2]] \n",
    "    point : set of points for polygon[x3,y3] \n",
    "    returns true or false\n",
    "    \"\"\"\n",
    "    p1 = Polygon(polygon)\n",
    "    return p1.contains(Point(point))\n",
    "\n",
    "\n",
    "def poly_intersection_shapely(pt1,pt2,intersection_threshold=.5):\n",
    "    \"\"\"\n",
    "    pt1 : set of points for polygon 1 [[x1,y1],[x2,y2]] \n",
    "    pt2 : set of points for polygon 2[[x1,y1],[x2,y2]] \n",
    "    intersection theshold : intersection threshold for polygon intersection considered with ref to pt2\n",
    "    bool : return True or False\n",
    "    \"\"\"\n",
    "\n",
    "    p1 = Polygon(pt1)\n",
    "    p2 = Polygon(pt2)\n",
    "    intersection_area = p1.intersection(p2).area\n",
    "    if intersection_area/p2.area>intersection_threshold:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_comb(bbox1,bbox2):\n",
    "    pts1 = np.array([[bbox1[0],bbox1[3]],[bbox1[2],bbox1[3]]])\n",
    "    pts2 = np.array([[bbox2[0],bbox2[3]],[bbox2[2],bbox2[3]]])\n",
    "    D = pairwise_distances(pts1,pts2,metric='euclidean')\n",
    "    coords = np.unravel_index(D.argmin(), D.shape)\n",
    "    return np.array([pts1[coords[0]],pts2[coords[1]]])\n",
    "\n",
    "def create_distance_arrow(frame, st_pt,end_pt,text,font=cv2.FONT_HERSHEY_SIMPLEX,font_scale=.8,font_thickness=2,font_color=(0,0,0),line_color=(255,255,255),display_category = False):\n",
    "    \"\"\"\n",
    "    frame on which distance matrix have to be created\n",
    "    st_pt : start point of line\n",
    "    end_pt : end point of line\n",
    "    text : text to write\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    (text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=font_thickness)[0]\n",
    "    if display_category:\n",
    "        ## assuming distance in meter and text is distance\n",
    "        distance = int(re.findall('\\d+',text)[0] )\n",
    "        if distance<100:\n",
    "            line_color = (0,0,255)\n",
    "        elif distance<200:\n",
    "            line_color = (0,255,255)\n",
    "        else :\n",
    "            line_color = (0,255,0)\n",
    "    op_frame = cv2.line(frame,tuple(st_pt),tuple(end_pt),line_color,font_thickness)\n",
    "    op_frame = cv2.putText(op_frame, text,tuple(((st_pt+end_pt)/2+np.array([0,text_height])).astype(int)) , font,  font_scale, font_color, font_thickness, cv2.LINE_AA) \n",
    "    return op_frame\n",
    "    \n",
    "\n",
    "def write_distance_frame(frame,bboxes,M,units =\"cm\"):\n",
    "    \"\"\"\n",
    "    frame : frame on which distance have to be write\n",
    "    bboxes :  bbox  array\n",
    "    M : Transformation matrix\n",
    "    \"\"\"\n",
    "    combs = list(combinations(list(range(bboxes.shape[0])),2))\n",
    "    for idx,comb in enumerate(combs):\n",
    "        pts_comb= get_closest_comb(bboxes[comb[0]],bboxes[comb[1]])\n",
    "        pts_comb_trans = cv2.perspectiveTransform(np.float32([pts_comb]),M).squeeze()\n",
    "        dist = int(sp.spatial.distance.euclidean(pts_comb_trans[0],pts_comb_trans[1]))\n",
    "        text = str(dist) \n",
    "        if units is not None:\n",
    "            text = text + units\n",
    "        frame = create_distance_arrow(frame,pts_comb[0],pts_comb[1],text,display_category = True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(frame,res_person,bbox,hv_results,thresh_hv=.5):\n",
    "    \"\"\"\n",
    "    frame :  frame for which results are generated \n",
    "    res_person :  person_detection model result\n",
    "    bbox : person detection bbox\n",
    "    res_hv : helmet vest model result\n",
    "    thresh_hv : helmet vest threshold\n",
    "    \"\"\"\n",
    "    res_person[:,1] = 6\n",
    "    res_all = []\n",
    "    for idx,res_hv in enumerate(hv_results):\n",
    "        res_hv = res_hv[0]\n",
    "        res_hv = res_hv[np.where(res_hv[:,:,:,2]>thresh_hv)]\n",
    "        if res_hv.shape[0]>0:\n",
    "                ##[1,2] helmet,no_helmet category\n",
    "                ##[3,4,5] vest,no_vest,worker \n",
    "            h_data = res_hv[np.isin(res_hv[:,1], [1,2])]\n",
    "            v_data = res_hv[np.isin(res_hv[:,1], [3,4,5])]\n",
    "            res_filt = []\n",
    "            try:\n",
    "                ## finding max for each category since there's only one person so one entry each category\n",
    "                if h_data.shape[0]!=0:\n",
    "                    res_filt.append(h_data[np.argmax(h_data[:,2])])\n",
    "                if v_data.shape[0]!=0:\n",
    "                    res_filt.append(v_data[np.argmax(v_data[:,2])])\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                #                 print(e)\n",
    "                            ####changing the bbox value from local to global\n",
    "            res_filt = np.array(res_filt)\n",
    "            b = bbox[idx]\n",
    "            width,height = b[2]-b[0] ,b[3]-b[1] \n",
    "            res_filt[:,3:] = [width,height,width,height]*res_filt[:,3:]+[b[0],b[1],b[0],b[1]]\n",
    "            res_filt[:,3:]/=np.array([frame.shape[1],frame.shape[0],frame.shape[1],frame.shape[0]])\n",
    "            res_all.append(res_filt)  \n",
    "    # pdb.set_trace()\n",
    "\n",
    "    res_all.append(res_person)\n",
    "    res_all = np.concatenate(res_all)\n",
    "    return res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class bbox_select():\n",
    "    %matplotlib widget \n",
    "\n",
    "\n",
    "    def __init__(self,im):\n",
    "        self.im = im\n",
    "        self.selected_points = []\n",
    "        self.fig,ax = plt.subplots()\n",
    "        self.img = ax.imshow(self.im.copy())\n",
    "        self.ka = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
    "        disconnect_button = widgets.Button(description=\"Disconnect mpl\")\n",
    "        Disp.display(disconnect_button)\n",
    "        disconnect_button.on_click(self.disconnect_mpl)\n",
    "\n",
    "\n",
    "        \n",
    "    def poly_img(self,img,pts):\n",
    "        pts = np.array(pts, np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        cv2.polylines(img,[pts],True,(0,255,255),4)\n",
    "        return img\n",
    "\n",
    "    def onclick(self, event):\n",
    "    #display(str(event))\n",
    "        self.selected_points.append([event.xdata,event.ydata])\n",
    "        if len(self.selected_points)>1:\n",
    "            self.fig\n",
    "            self.img.set_data(self.poly_img(self.im.copy(),self.selected_points))\n",
    "    def disconnect_mpl(self,_):\n",
    "        self.fig.canvas.mpl_disconnect(self.ka)\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = \"/home/prateek/prateek_space/helmet_n_vest/test_data/2019_09_12_Taloja_video_data/2019-09-12/annealing_view/comb_output.mp4\"\n",
    "cap = cv2.VideoCapture(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0fcfc66f044fa6adf12732319c0d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af1979838f14e5799ce81a4c90c1a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Disconnect mpl', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret,frame = cap.read()\n",
    "\n",
    "bs = bbox_select(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[652.4354366179434, 1059.7580467962448],\n",
       " [1380.1773721018144, 614.5967564736642],\n",
       " [1693.7257591985885, 626.2096596994706],\n",
       " [1349.2096301663305, 1063.6290145381804]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.selected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 450\n",
    "height = 2320\n",
    "\n",
    "\n",
    "final_points = [[0,0],[width,0],[width,height],[0,height]]\n",
    "\n",
    "\n",
    "M = cv2.getPerspectiveTransform(np.float32(bs.selected_points),np.float32(final_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = \"/home/prateek/prateek_space/helmet_n_vest/test_data/2019_09_12_Taloja_video_data/2019-09-12/annealing_view/comb_output.mp4\"\n",
    "cap = cv2.VideoCapture(channel)\n",
    "thresh_person = .3\n",
    "res_range = [.002,.03]\n",
    "intersection_thresh = .1\n",
    "show_bbox = True\n",
    "fps_async = []\n",
    "f_name = 1\n",
    "while True:\n",
    "    t0 = time.time()\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    person_vehicle_model.predict(frame)\n",
    "    if person_vehicle_model.frame_processed>=person_vehicle_model.num_requests:\n",
    "        frame,attr,res = person_vehicle_model.postprocess_op()\n",
    "        \n",
    "        op,bboxes,res_filt = output_support.trim_frame_with_result(frame,res[0],threshold=thresh_person,return_results = True,resolution_thresh_range = res_range)\n",
    "        for im in op:\n",
    "            cv2.imwrite(str(f_name).zfill(5)+\"_.jpg\",im)\n",
    "            f_name+=1\n",
    "        if len(bboxes)>1:\n",
    "        #         D =pairwise_distances(cv2.perspectiveTransform(np.float32([bboxes[:,2:]]),M).squeeze()).astype(int)\n",
    "            frame = write_distance_frame(frame,np.array(bboxes),M)\n",
    "        \n",
    "        if show_bbox:\n",
    "            frame = cv2.polylines(frame,[np.reshape(bs.selected_points,(-1,1,2)).astype('int32')],True,(255,255,0),2,cv2.LINE_AA)\n",
    "        for b in bboxes:\n",
    "            if poly_intersection_shapely(bs.selected_points,[[b[0],b[1]],[b[2],b[1]],[b[2],b[3]],[b[0],b[3]]],intersection_threshold=intersection_thresh)and(point_intersection_shapely(bs.selected_points,[b[0],b[3]]) or point_intersection_shapely(bs.selected_points,[b[2],b[3]])):\n",
    "                cv2.rectangle(frame, (b[0], b[1]), (b[2], b[3]), (0,0,255), 2)            \n",
    "            else:\n",
    "                # if not intersecting\n",
    "                #pass\n",
    "                cv2.rectangle(frame, (b[0], b[1]), (b[2], b[3]), (0,0,0), 2)\n",
    "        fps_async.append(1/(time.time()-t0))\n",
    "        frame = output_support.write_text(frame,\"FPS :%.2f\"%np.median(fps_async),text_color=(0, 0, 0),font_scale=1)\n",
    "        cv2.imshow(\"output\",frame)\n",
    "        k = cv2.waitKey(1)\n",
    "        if k==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[413, 68, 442, 104]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[413, 68, 442, 104]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
