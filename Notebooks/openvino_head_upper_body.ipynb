{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:16.003566Z",
     "start_time": "2019-09-27T11:39:12.726988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/.virtualenvs/openvino/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'openvino.inference_engine.ie_api' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser, SUPPRESS\n",
    "import cv2,threading\n",
    "import time,datetime\n",
    "import logging as log\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "import numpy as np\n",
    "from multiprocessing import Process,Pool\n",
    "import shutil,pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:16.015152Z",
     "start_time": "2019-09-27T11:39:16.009696Z"
    }
   },
   "outputs": [],
   "source": [
    "###output\n",
    "# batch index\n",
    "# class label\n",
    "# class probability\n",
    "# x_1 box coordinate\n",
    "# y_1 box coordinate\n",
    "# x_2 box coordinate\n",
    "# y_2 box coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:16.126355Z",
     "start_time": "2019-09-27T11:39:16.019029Z"
    }
   },
   "outputs": [],
   "source": [
    "m_fcnn = '../model_files/head_upper_body/frozen_inference_graph.xml'\n",
    "channel = 'rtsp://admin:admin@123@10.10.12.14:554/Streaming/Channels/401/'\n",
    "cpu_extension = '../build_samples/intel64/Release/lib/libcpu_extension.so'\n",
    "device = 'CPU'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:17.133883Z",
     "start_time": "2019-09-27T11:39:16.132476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plugin initialization for specified device and load extensions library if specified\n",
    "log.info(\"Initializing plugin for {} device...\".format('CPU'))\n",
    "plugin = IEPlugin(device='CPU')\n",
    "if cpu_extension and 'CPU' in device:\n",
    "    plugin.add_cpu_extension(cpu_extension)\n",
    "# Read IR\n",
    "log.info(\"Reading IR...\")\n",
    "m_fcnn_net= IENetwork(model=m_fcnn, weights=os.path.splitext(m_fcnn)[0] + \".bin\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:17.169375Z",
     "start_time": "2019-09-27T11:39:17.139178Z"
    }
   },
   "outputs": [],
   "source": [
    "if device == \"CPU\":\n",
    "    for net in [m_fcnn_net]:\n",
    "        supported_layers = plugin.get_supported_layers(net)\n",
    "        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "        if len(not_supported_layers) != 0:\n",
    "            log.error(\"Following layers are not supported by the plugin for specified device {}:\\n {}\".\n",
    "                      format(plugin.device, ', '.join(not_supported_layers)))\n",
    "            log.error(\"Please try to specify cpu extensions library path in demo's command line parameters using -l \"\n",
    "                      \"or --cpu_extension command line argument\")\n",
    "            sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:17.740703Z",
     "start_time": "2019-09-27T11:39:17.172433Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 300 3 300\n"
     ]
    }
   ],
   "source": [
    "input_blob = []\n",
    "out_blob = []\n",
    "exec_net = []\n",
    "for i,net in enumerate([m_fcnn_net]):\n",
    "    # assert len(net.inputs.keys()) == 1, \"Demo supports only single input topologies\"\n",
    "    # assert len(net.outputs) == 1, \"Demo supports only single output topologies\"\n",
    "    input_blob.append(next(iter(net.inputs)))\n",
    "    out_blob.append(next(iter(net.outputs)))\n",
    "    log.info(\"Loading IR to the plugin...\")\n",
    "    exec_net.append(plugin.load(network=net, num_requests=2))\n",
    "    # Read and pre-process input image\n",
    "\n",
    "n, c, h, w = net.inputs['image_tensor'].shape\n",
    "print(n,h,c,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:17.837034Z",
     "start_time": "2019-09-27T11:39:17.742932Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_detection(input_frame,n=1,c=3,w=300,h=300,thresh=.1):\n",
    "    op_frame = cv2.resize(input_frame,(w,h)).transpose((2, 0, 1)).reshape(n,c,h,w) \n",
    "    ### we can add multiple requests and just enumerate request ids\n",
    "    exec_net[0].start_async(request_id=1, inputs={input_blob[0]:op_frame})\n",
    "    if exec_net[0].requests[1].wait(-1)==0:\n",
    "        res = exec_net[0].requests[1].outputs[out_blob[0]]\n",
    "    res_filt =  res[np.where(res[:,:,:,2]>thresh)]\n",
    "    res_filt = res_filt[np.min(res_filt,axis=1)>=0]\n",
    "    return res_filt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:17.926747Z",
     "start_time": "2019-09-27T11:39:17.843951Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_to_names = {0: 'person', 1: 'head', 2: 'upper_body'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:18.002627Z",
     "start_time": "2019-09-27T11:39:17.930964Z"
    }
   },
   "outputs": [],
   "source": [
    "colors_labels = pd.read_pickle('retinanet_coco_labels_colors.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:18.074712Z",
     "start_time": "2019-09-27T11:39:18.007457Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_plot(in_frame,thresh=.2):\n",
    "    \"\"\"\n",
    "    person,0   \n",
    "    helmet,1   \n",
    "    no_helmet,2\n",
    "    vest,3     \n",
    "    no_vest,4  \n",
    "    worker,5  \n",
    "    \"\"\"\n",
    "    initial_h,initial_w = in_frame.shape[:2]\n",
    "    res_filt = generate_detection(frame,thresh=thresh)\n",
    "    bboxes = np.multiply([[initial_w,initial_h,initial_w,initial_h]],(res_filt[:,3:])).astype('int')\n",
    "    #colors = [(0,0,0),(0,255,0),(0,0,255),(0,255,0),(0,0,255),(255,0,0)]\n",
    "    labels = res_filt[:,1].astype(int).flatten()\n",
    "#     print(labels)\n",
    "    for idx,b in enumerate(bboxes):\n",
    "        #print(idx,res_filt,bboxes)\n",
    "        in_frame = cv2.rectangle(in_frame, (b[0], b[1]), (b[2], b[3]),colors_labels.loc[labels[idx]-1]['colors'] , 2)\n",
    "        cv2.putText(frame, labels_to_names[labels[idx]-1], (b[0]-15,b[1]-15), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "            (10, 10, 200), 1)\n",
    "    return in_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:18.170232Z",
     "start_time": "2019-09-27T11:39:18.079759Z"
    }
   },
   "outputs": [],
   "source": [
    "channel = 'rtsp://user:operator@123@10.36.12.122:554/Streaming/Channels/1601/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:18.246371Z",
     "start_time": "2019-09-27T11:39:18.174692Z"
    }
   },
   "outputs": [],
   "source": [
    "channel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T11:39:22.426413Z",
     "start_time": "2019-09-27T11:39:18.248432Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Detection Results\",cv2.WINDOW_NORMAL)\n",
    "fd_thresh = .1\n",
    "# if labels:\n",
    "#     with open(labels, 'r') as f:\n",
    "#         labels_map = [x.strip() for x in f]\n",
    "# else:\n",
    "#     labels_map = None\n",
    "write_video = False\n",
    "if write_video:\n",
    "    out = None\n",
    "cap = cv2.VideoCapture(channel)\n",
    "retry_connect = 10\n",
    "cur_request_id = 0\n",
    "fps_fd = []\n",
    "net_fps = []\n",
    "while (cap.isOpened()):\n",
    "    fps_fd = fps_fd[-100:]\n",
    "    initial_w = cap.get(3)\n",
    "    initial_h = cap.get(4)\n",
    "    inf_start_fd = time.time()\n",
    "    for i in range(10):\n",
    "        ret,frame  = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(channel)\n",
    "        retry_connect-=1\n",
    "        if retry_connect<0:\n",
    "            break\n",
    "        \n",
    "    # preprocess image for network\n",
    "#     frame = preprocess_image(frame)\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #image, scale = resize_image(image)\n",
    "    \n",
    "    frame = generate_plot(frame,thresh=.3)\n",
    "    \n",
    "    det_time_fd = time.time()- inf_start_fd\n",
    "\n",
    "    fps_fd.append(1/det_time_fd)\n",
    "    cv2.putText(frame, \"Inference FPS  detection: {:.3f} \".format(np.mean(fps_fd)), (10, int(initial_h - 50)), cv2.FONT_HERSHEY_COMPLEX, 0.5,\n",
    "            (10, 10, 200), 1)\n",
    "    net_fps.append(np.mean(fps_fd))\n",
    "    \n",
    "    #\n",
    "    if write_video:\n",
    "        if out is None:\n",
    "            out = cv2.VideoWriter('../output_vids/'+datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_\")+os.path.basename(channel)+'_out.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (frame.shape[1],frame.shape[0]))\n",
    "        out.write(frame)\n",
    "    cv2.imshow(\"Detection Results\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27 :\n",
    "        break\n",
    "if write_video:\n",
    "    out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
